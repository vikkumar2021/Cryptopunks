{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0160d80",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'rolling_20_day_avg' given input columns: [btc_transform1.Adj_Close, btc_transform1.Close, btc_transform1.High, btc_transform1.Low, btc_transform1.Open, btc_transform1.Ticker, btc_transform1.TradeDate, btc_transform1.Volume, bollinger_band_lower, bollinger_band_upper, btc_transform1.bollinger_rolling_avg, btc_transform1.bollinger_rolling_std, btc_transform1.rolling_7_day_avg];\n'Project [TradeDate#673, 'rolling_20_day_avg, bollinger_band_lower#690, bollinger_band_upper#691]\n+- WithCTE\n   :- CTERelationDef 3\n   :  +- SubqueryAlias btc_transform1\n   :     +- Project [TradeDate#673, Open#652, High#653, Low#654, Close#655, Adj_Close#665, Volume#657L, Ticker#681, rolling_7_day_avg#692, bollinger_rolling_avg#693, bollinger_rolling_std#694]\n   :        +- Project [TradeDate#673, Open#652, High#653, Low#654, Close#655, Adj_Close#665, Volume#657L, Ticker#681, _w0#714, rolling_7_day_avg#692, bollinger_rolling_avg#693, bollinger_rolling_std#694, rolling_7_day_avg#692, bollinger_rolling_avg#693, bollinger_rolling_std#694]\n   :           +- Window [avg(Open#652) windowspecdefinition(Ticker#681, TradeDate#673 ASC NULLS FIRST, specifiedwindowframe(RangeFrame, -INTERVAL '7' DAY, currentrow$())) AS rolling_7_day_avg#692, avg(Close#655) windowspecdefinition(Ticker#681, TradeDate#673 ASC NULLS FIRST, specifiedwindowframe(RangeFrame, -INTERVAL '20' DAY, currentrow$())) AS bollinger_rolling_avg#693, stddev(_w0#714) windowspecdefinition(Ticker#681, TradeDate#673 ASC NULLS FIRST, specifiedwindowframe(RangeFrame, -INTERVAL '20' DAY, currentrow$())) AS bollinger_rolling_std#694], [Ticker#681], [TradeDate#673 ASC NULLS FIRST]\n   :              +- Project [TradeDate#673, Open#652, High#653, Low#654, Close#655, Adj_Close#665, Volume#657L, Ticker#681, cast(Close#655 as double) AS _w0#714]\n   :                 +- SubqueryAlias btc\n   :                    +- View (`btc`, [TradeDate#673,Open#652,High#653,Low#654,Close#655,Adj_Close#665,Volume#657L,Ticker#681])\n   :                       +- Project [TradeDate#673, Open#652, High#653, Low#654, Close#655, Adj_Close#665, Volume#657L, BTC AS Ticker#681]\n   :                          +- Project [Date#651 AS TradeDate#673, Open#652, High#653, Low#654, Close#655, Adj_Close#665, Volume#657L]\n   :                             +- Project [Date#651, Open#652, High#653, Low#654, Close#655, Adj Close#656 AS Adj_Close#665, Volume#657L]\n   :                                +- Relation [Date#651,Open#652,High#653,Low#654,Close#655,Adj Close#656,Volume#657L] csv\n   +- Project [TradeDate#673, Open#652, High#653, Low#654, Close#655, Adj_Close#665, Volume#657L, Ticker#681, rolling_7_day_avg#692, bollinger_rolling_avg#693, bollinger_rolling_std#694, (cast(bollinger_rolling_avg#693 as double) - (bollinger_rolling_std#694 * cast(2 as double))) AS bollinger_band_lower#690, (cast(bollinger_rolling_avg#693 as double) + (bollinger_rolling_std#694 * cast(2 as double))) AS bollinger_band_upper#691]\n      +- SubqueryAlias btc_transform1\n         +- CTERelationRef 3, true, [TradeDate#673, Open#652, High#653, Low#654, Close#655, Adj_Close#665, Volume#657L, Ticker#681, rolling_7_day_avg#692, bollinger_rolling_avg#693, bollinger_rolling_std#694]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 172>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m df_price \u001b[38;5;241m=\u001b[39m transform_stock_price_data(df_price_raw)\n\u001b[1;32m    176\u001b[0m price_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTradeDate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    177\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrolling_20_day_avg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    178\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbollinger_band_lower\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    179\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbollinger_band_upper\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 180\u001b[0m \u001b[43mdf_price\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprice_cols\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    181\u001b[0m df_tweets \u001b[38;5;241m=\u001b[39m read_tweets_data(spark, TWEETS_FILE_PATH)\n\u001b[1;32m    182\u001b[0m df_sentiment \u001b[38;5;241m=\u001b[39m analyze_tweet_sentiment(df_tweets)\n",
      "File \u001b[0;32m~/code/GA_Tech/CSE6242/.venv_cse6242/lib/python3.8/site-packages/pyspark/sql/dataframe.py:1685\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols):\n\u001b[1;32m   1665\u001b[0m     \u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \n\u001b[1;32m   1667\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;124;03m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1685\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m~/code/GA_Tech/CSE6242/.venv_cse6242/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/code/GA_Tech/CSE6242/.venv_cse6242/lib/python3.8/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve 'rolling_20_day_avg' given input columns: [btc_transform1.Adj_Close, btc_transform1.Close, btc_transform1.High, btc_transform1.Low, btc_transform1.Open, btc_transform1.Ticker, btc_transform1.TradeDate, btc_transform1.Volume, bollinger_band_lower, bollinger_band_upper, btc_transform1.bollinger_rolling_avg, btc_transform1.bollinger_rolling_std, btc_transform1.rolling_7_day_avg];\n'Project [TradeDate#673, 'rolling_20_day_avg, bollinger_band_lower#690, bollinger_band_upper#691]\n+- WithCTE\n   :- CTERelationDef 3\n   :  +- SubqueryAlias btc_transform1\n   :     +- Project [TradeDate#673, Open#652, High#653, Low#654, Close#655, Adj_Close#665, Volume#657L, Ticker#681, rolling_7_day_avg#692, bollinger_rolling_avg#693, bollinger_rolling_std#694]\n   :        +- Project [TradeDate#673, Open#652, High#653, Low#654, Close#655, Adj_Close#665, Volume#657L, Ticker#681, _w0#714, rolling_7_day_avg#692, bollinger_rolling_avg#693, bollinger_rolling_std#694, rolling_7_day_avg#692, bollinger_rolling_avg#693, bollinger_rolling_std#694]\n   :           +- Window [avg(Open#652) windowspecdefinition(Ticker#681, TradeDate#673 ASC NULLS FIRST, specifiedwindowframe(RangeFrame, -INTERVAL '7' DAY, currentrow$())) AS rolling_7_day_avg#692, avg(Close#655) windowspecdefinition(Ticker#681, TradeDate#673 ASC NULLS FIRST, specifiedwindowframe(RangeFrame, -INTERVAL '20' DAY, currentrow$())) AS bollinger_rolling_avg#693, stddev(_w0#714) windowspecdefinition(Ticker#681, TradeDate#673 ASC NULLS FIRST, specifiedwindowframe(RangeFrame, -INTERVAL '20' DAY, currentrow$())) AS bollinger_rolling_std#694], [Ticker#681], [TradeDate#673 ASC NULLS FIRST]\n   :              +- Project [TradeDate#673, Open#652, High#653, Low#654, Close#655, Adj_Close#665, Volume#657L, Ticker#681, cast(Close#655 as double) AS _w0#714]\n   :                 +- SubqueryAlias btc\n   :                    +- View (`btc`, [TradeDate#673,Open#652,High#653,Low#654,Close#655,Adj_Close#665,Volume#657L,Ticker#681])\n   :                       +- Project [TradeDate#673, Open#652, High#653, Low#654, Close#655, Adj_Close#665, Volume#657L, BTC AS Ticker#681]\n   :                          +- Project [Date#651 AS TradeDate#673, Open#652, High#653, Low#654, Close#655, Adj_Close#665, Volume#657L]\n   :                             +- Project [Date#651, Open#652, High#653, Low#654, Close#655, Adj Close#656 AS Adj_Close#665, Volume#657L]\n   :                                +- Relation [Date#651,Open#652,High#653,Low#654,Close#655,Adj Close#656,Volume#657L] csv\n   +- Project [TradeDate#673, Open#652, High#653, Low#654, Close#655, Adj_Close#665, Volume#657L, Ticker#681, rolling_7_day_avg#692, bollinger_rolling_avg#693, bollinger_rolling_std#694, (cast(bollinger_rolling_avg#693 as double) - (bollinger_rolling_std#694 * cast(2 as double))) AS bollinger_band_lower#690, (cast(bollinger_rolling_avg#693 as double) + (bollinger_rolling_std#694 * cast(2 as double))) AS bollinger_band_upper#691]\n      +- SubqueryAlias btc_transform1\n         +- CTERelationRef 3, true, [TradeDate#673, Open#652, High#653, Low#654, Close#655, Adj_Close#665, Volume#657L, Ticker#681, rolling_7_day_avg#692, bollinger_rolling_avg#693, bollinger_rolling_std#694]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import TimestampType, DecimalType, LongType, StructType, StructField, MapType, StringType, DoubleType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import json\n",
    "\n",
    "\n",
    "PRICE_FILE_PATH = '/Users/salmanmukhi/Downloads/BTC-USD_2017-2022.csv'\n",
    "TWEETS_FILE_PATH = '/Users/salmanmukhi/Downloads/BTC_tweets.csv'\n",
    "\n",
    "\n",
    "def create_spark_session():\n",
    "    \"\"\"Create Spark Session\"\"\"\n",
    "\n",
    "    return (SparkSession\n",
    "            .builder\n",
    "            .appName('test')\n",
    "            .master(\"local[*]\")\n",
    "            .enableHiveSupport()\n",
    "            .getOrCreate()\n",
    "           )\n",
    "\n",
    "\n",
    "def read_stock_price_data(spark: SparkSession, file_path: str) -> DataFrame:\n",
    "    \"\"\"Read stock price CSV file from Yahoo Finance\"\"\"\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField(\"Date\", TimestampType(), True),\n",
    "        StructField(\"Open\", DecimalType(10,2), True),\n",
    "        StructField(\"High\", DecimalType(10,2), True),\n",
    "        StructField(\"Low\", DecimalType(10,2), True),\n",
    "        StructField(\"Close\", DecimalType(10,2), True),\n",
    "        StructField(\"Adj Close\", DecimalType(10,2), True),\n",
    "        StructField(\"Volume\", LongType(), True),\n",
    "    ])\n",
    "    df = (spark.read.csv(PRICE_FILE_PATH, header=True, schema=schema)\n",
    "        .withColumnRenamed(\"Adj Close\", \"Adj_Close\")\n",
    "        .withColumnRenamed(\"Date\", \"TradeDate\")\n",
    "        .withColumn(\"Ticker\", F.lit(\"BTC\"))\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_tweets_data(spark: SparkSession, file_path: str) -> DataFrame:\n",
    "    \"\"\"Read raw tweets CSV file\"\"\"\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField(\"id\",StringType(),True),\n",
    "        StructField(\"user\",StringType(),True),\n",
    "        StructField(\"fullname\",StringType(),True),\n",
    "        StructField(\"url\",StringType(),True),\n",
    "        StructField(\"timestamp\",TimestampType(),True),\n",
    "        StructField(\"replies\",StringType(),True),\n",
    "        StructField(\"likes\",LongType(),True),\n",
    "        StructField(\"retweets\",LongType(),True),\n",
    "        StructField(\"text\",StringType(),True)]\n",
    "    )\n",
    "    tweets_df = (spark\n",
    "        .read\n",
    "        .option('delimiter', ';')\n",
    "        .csv(file_path, header=True, schema=schema))\n",
    "    \n",
    "    # TODO: Remove Limit on Dataframe when running on cluster\n",
    "    tweets_df_subset = tweets_df.limit(50000)\n",
    "\n",
    "    return (tweets_df_subset\n",
    "        .withColumnRenamed(\"timestamp\", \"tweet_timestamp\")\n",
    "        .where('text IS NOT NULL'))\n",
    "\n",
    "\n",
    "def transform_stock_price_data(df: DataFrame,\n",
    "                               window: int = 7,\n",
    "                               bollinger_window: int = 20,\n",
    "                               bollinger_stdvs: int = 2) -> DataFrame:\n",
    "    \"\"\"Add rolling averages and Bollinger Bands to dataframe\"\"\"\n",
    "\n",
    "    df.createOrReplaceTempView('btc')\n",
    "    df_transformed = spark.sql(f\"\"\"\n",
    "        WITH btc_transform1 AS\n",
    "            (SELECT\n",
    "            *,\n",
    "            AVG(Open) OVER(\n",
    "                PARTITION BY Ticker\n",
    "                ORDER BY TradeDate ASC\n",
    "                RANGE BETWEEN INTERVAL {window} DAYS PRECEDING AND CURRENT ROW) AS rolling_{window}_day_avg,\n",
    "            AVG(Close) OVER(\n",
    "                PARTITION BY Ticker\n",
    "                ORDER BY TradeDate ASC\n",
    "                RANGE BETWEEN INTERVAL {bollinger_window} DAYS PRECEDING AND CURRENT ROW) AS bollinger_rolling_avg,\n",
    "            STDDEV(Close) OVER(\n",
    "                PARTITION BY Ticker\n",
    "                ORDER BY TradeDate ASC\n",
    "                RANGE BETWEEN INTERVAL {bollinger_window} DAYS PRECEDING AND CURRENT ROW) AS bollinger_rolling_std\n",
    "            FROM btc)\n",
    "\n",
    "        SELECT\n",
    "        *,\n",
    "        (bollinger_rolling_avg - (bollinger_rolling_std * {bollinger_stdvs})) AS bollinger_band_lower,\n",
    "        (bollinger_rolling_avg + (bollinger_rolling_std * {bollinger_stdvs})) AS bollinger_band_upper\n",
    "        FROM btc_transform1\n",
    "        \"\"\")\n",
    "    \n",
    "    return df_transformed\n",
    "\n",
    "\n",
    "def analyze_tweet_sentiment(tweets_df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "        Use NLTK's pretrained SentimentIntensityAnalyzer to measure the sentiment\n",
    "        of each tweet. Filter out tweets such as those in different languages that will default to a score\n",
    "        of neutral=1.0.\n",
    "    \"\"\"\n",
    "    \n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Wrap function in UDF\n",
    "    def get_tweet_sentiment(tweet: str) -> str:\n",
    "        sentiment_score = sia.polarity_scores(tweet)\n",
    "        return json.dumps(sentiment_score)\n",
    "\n",
    "    sentiment_udf = F.udf(get_tweet_sentiment, StringType())\n",
    "    # sentiment_udf = F.udf(get_tweet_sentiment, MapType(StringType(), DoubleType()))\n",
    "    return (tweets_df\n",
    "        .withColumn('tweets_analyzed', sentiment_udf('text'))\n",
    "        .select(\"*\",\n",
    "            F.get_json_object('tweets_analyzed', '$.neg').cast(DecimalType(4,3)).alias('negative'),\n",
    "            F.get_json_object('tweets_analyzed', '$.neu').cast(DecimalType(4,3)).alias('neutral'),\n",
    "            F.get_json_object('tweets_analyzed', '$.pos').cast(DecimalType(4,3)).alias('positive'),\n",
    "            F.get_json_object('tweets_analyzed', '$.compound').cast(DecimalType(4,3)).alias('compound')\n",
    "        )\n",
    "        .where('neutral != 1.0')\n",
    "    )\n",
    "\n",
    "\n",
    "def aggregate_tweet_sentiment(df):\n",
    "    \"\"\"Aggregate sentiment data from individual tweets to a daily level of granularity\"\"\"\n",
    "\n",
    "    df.createOrReplaceTempView('tweet_sentiment_unagg')\n",
    "    df_agg = spark.sql(\"\"\"\n",
    "    WITH tweet_sentiment_labaled AS\n",
    "        (SELECT CAST(tweet_timestamp AS Date) AS tweet_date,\n",
    "            CASE\n",
    "                WHEN negative > positive\n",
    "                    AND negative > neutral\n",
    "                    THEN 'negative'\n",
    "                WHEN positive > negative\n",
    "                    AND positive > neutral\n",
    "                    THEN 'positive'\n",
    "                WHEN neutral > positive\n",
    "                    AND neutral > negative\n",
    "                    THEN 'neutral'\n",
    "                END AS overall_sentiment\n",
    "        FROM\n",
    "            tweet_sentiment_unagg)\n",
    "    \n",
    "    SELECT\n",
    "        tweet_date,\n",
    "        AVG(CASE WHEN overall_sentiment = 'positive' THEN 1 ELSE 0 END) AS pct_positive,\n",
    "        AVG(CASE WHEN overall_sentiment = 'negative' THEN 1 ELSE 0 END) AS pct_negative,\n",
    "        AVG(CASE WHEN overall_sentiment = 'neutral' THEN 1 ELSE 0 END) AS pct_neutral,\n",
    "        COUNT(*) AS tweet_volume\n",
    "    FROM\n",
    "        tweet_sentiment_labaled\n",
    "    GROUP BY tweet_date\n",
    "    \"\"\")\n",
    "    \n",
    "    return df_agg\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = create_spark_session()\n",
    "    df_price_raw = read_stock_price_data(spark, PRICE_FILE_PATH)\n",
    "    df_price = transform_stock_price_data(df_price_raw)\n",
    "    price_cols = [\"TradeDate\",\n",
    "                  \"rolling_20_day_avg\",\n",
    "                  \"bollinger_band_lower\",\n",
    "                  \"bollinger_band_upper\"]\n",
    "    df_price.select(price_cols).show()\n",
    "    df_tweets = read_tweets_data(spark, TWEETS_FILE_PATH)\n",
    "    df_sentiment = analyze_tweet_sentiment(df_tweets)\n",
    "    df_sentiment.printSchema()\n",
    "    tweet_cols = ['tweet_timestamp',\n",
    "                  'likes',\n",
    "                  'retweets',\n",
    "                  'negative',\n",
    "                  'positive',\n",
    "                  'neutral',\n",
    "                  'compound']\n",
    "    df_sentiment.select(tweet_cols).show()\n",
    "    df_agg_sentiment = aggregate_tweet_sentiment(df_sentiment)\n",
    "    df_agg_sentiment.show()\n",
    "    \n",
    "    df_joined = df_price.join(df_agg_sentiment, df_price.TradeDate == df_agg_sentiment.tweet_date, 'inner')\n",
    "    df_joined.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e71e8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TradeDate</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>rolling_7_day_avg</th>\n",
       "      <th>rolling_200_day_avg</th>\n",
       "      <th>rolling_20_day_avg</th>\n",
       "      <th>rolling_20_day_std</th>\n",
       "      <th>bollinger_band_lower</th>\n",
       "      <th>bollinger_band_upper</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>pct_positive</th>\n",
       "      <th>pct_negative</th>\n",
       "      <th>pct_neutral</th>\n",
       "      <th>tweet_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>5849.48</td>\n",
       "      <td>5989.98</td>\n",
       "      <td>5794.72</td>\n",
       "      <td>5982.46</td>\n",
       "      <td>5982.46</td>\n",
       "      <td>15320605300</td>\n",
       "      <td>BTC</td>\n",
       "      <td>5655.740000</td>\n",
       "      <td>4469.216716</td>\n",
       "      <td>4466.955473</td>\n",
       "      <td>996.010342</td>\n",
       "      <td>3470.945131</td>\n",
       "      <td>5462.965815</td>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>7044.81</td>\n",
       "      <td>7242.29</td>\n",
       "      <td>7038.05</td>\n",
       "      <td>7193.25</td>\n",
       "      <td>7193.25</td>\n",
       "      <td>4116050000</td>\n",
       "      <td>BTC</td>\n",
       "      <td>6903.840000</td>\n",
       "      <td>7910.455075</td>\n",
       "      <td>7901.675124</td>\n",
       "      <td>1377.102412</td>\n",
       "      <td>6524.572712</td>\n",
       "      <td>9278.777536</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>8674.07</td>\n",
       "      <td>8907.17</td>\n",
       "      <td>8668.71</td>\n",
       "      <td>8805.78</td>\n",
       "      <td>8805.78</td>\n",
       "      <td>27949839564</td>\n",
       "      <td>BTC</td>\n",
       "      <td>8051.415000</td>\n",
       "      <td>4575.811592</td>\n",
       "      <td>4587.443980</td>\n",
       "      <td>1284.345026</td>\n",
       "      <td>3303.098954</td>\n",
       "      <td>5871.789006</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>0.062903</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-28</td>\n",
       "      <td>5271.75</td>\n",
       "      <td>5326.23</td>\n",
       "      <td>5255.68</td>\n",
       "      <td>5285.14</td>\n",
       "      <td>5285.14</td>\n",
       "      <td>12819992056</td>\n",
       "      <td>BTC</td>\n",
       "      <td>5355.911250</td>\n",
       "      <td>4512.795373</td>\n",
       "      <td>4506.320995</td>\n",
       "      <td>1055.109045</td>\n",
       "      <td>3451.211950</td>\n",
       "      <td>5561.430040</td>\n",
       "      <td>2019-04-28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-17</td>\n",
       "      <td>4047.72</td>\n",
       "      <td>4054.12</td>\n",
       "      <td>4006.41</td>\n",
       "      <td>4025.23</td>\n",
       "      <td>4025.23</td>\n",
       "      <td>8221625400</td>\n",
       "      <td>BTC</td>\n",
       "      <td>3947.572500</td>\n",
       "      <td>4905.297015</td>\n",
       "      <td>4890.617313</td>\n",
       "      <td>1359.438495</td>\n",
       "      <td>3531.178818</td>\n",
       "      <td>6250.055808</td>\n",
       "      <td>2019-03-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>4105.46</td>\n",
       "      <td>4113.02</td>\n",
       "      <td>4094.10</td>\n",
       "      <td>4105.40</td>\n",
       "      <td>4105.40</td>\n",
       "      <td>9045122443</td>\n",
       "      <td>BTC</td>\n",
       "      <td>4045.777500</td>\n",
       "      <td>4710.204776</td>\n",
       "      <td>4699.571393</td>\n",
       "      <td>1263.280727</td>\n",
       "      <td>3436.290666</td>\n",
       "      <td>5962.852120</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>5061.20</td>\n",
       "      <td>5103.27</td>\n",
       "      <td>4955.85</td>\n",
       "      <td>5089.54</td>\n",
       "      <td>5089.54</td>\n",
       "      <td>13675206312</td>\n",
       "      <td>BTC</td>\n",
       "      <td>5137.817500</td>\n",
       "      <td>4617.933333</td>\n",
       "      <td>4610.129204</td>\n",
       "      <td>1183.201823</td>\n",
       "      <td>3426.927381</td>\n",
       "      <td>5793.331027</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>8194.50</td>\n",
       "      <td>8320.82</td>\n",
       "      <td>7729.61</td>\n",
       "      <td>7884.91</td>\n",
       "      <td>7884.91</td>\n",
       "      <td>33167197581</td>\n",
       "      <td>BTC</td>\n",
       "      <td>7088.031250</td>\n",
       "      <td>4493.505323</td>\n",
       "      <td>4500.628308</td>\n",
       "      <td>1084.723988</td>\n",
       "      <td>3415.904320</td>\n",
       "      <td>5585.352296</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>4156.92</td>\n",
       "      <td>4905.95</td>\n",
       "      <td>4155.32</td>\n",
       "      <td>4879.88</td>\n",
       "      <td>4879.88</td>\n",
       "      <td>21315047816</td>\n",
       "      <td>BTC</td>\n",
       "      <td>4071.153750</td>\n",
       "      <td>4688.269602</td>\n",
       "      <td>4680.511443</td>\n",
       "      <td>1251.787127</td>\n",
       "      <td>3428.724316</td>\n",
       "      <td>5932.298570</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>5466.52</td>\n",
       "      <td>5542.24</td>\n",
       "      <td>5181.34</td>\n",
       "      <td>5210.52</td>\n",
       "      <td>5210.52</td>\n",
       "      <td>15330283408</td>\n",
       "      <td>BTC</td>\n",
       "      <td>5367.445000</td>\n",
       "      <td>4533.105970</td>\n",
       "      <td>4526.545075</td>\n",
       "      <td>1082.471052</td>\n",
       "      <td>3444.074023</td>\n",
       "      <td>5609.016127</td>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TradeDate     Open     High      Low    Close Adj_Close       Volume  \\\n",
       "0  2019-05-08  5849.48  5989.98  5794.72  5982.46   5982.46  15320605300   \n",
       "1  2018-09-01  7044.81  7242.29  7038.05  7193.25   7193.25   4116050000   \n",
       "2  2019-05-27  8674.07  8907.17  8668.71  8805.78   8805.78  27949839564   \n",
       "3  2019-04-28  5271.75  5326.23  5255.68  5285.14   5285.14  12819992056   \n",
       "4  2019-03-17  4047.72  4054.12  4006.41  4025.23   4025.23   8221625400   \n",
       "..        ...      ...      ...      ...      ...       ...          ...   \n",
       "61 2019-03-31  4105.46  4113.02  4094.10  4105.40   4105.40   9045122443   \n",
       "62 2019-04-12  5061.20  5103.27  4955.85  5089.54   5089.54  13675206312   \n",
       "63 2019-05-16  8194.50  8320.82  7729.61  7884.91   7884.91  33167197581   \n",
       "64 2019-04-02  4156.92  4905.95  4155.32  4879.88   4879.88  21315047816   \n",
       "65 2019-04-25  5466.52  5542.24  5181.34  5210.52   5210.52  15330283408   \n",
       "\n",
       "   Ticker rolling_7_day_avg rolling_200_day_avg rolling_20_day_avg  \\\n",
       "0     BTC       5655.740000         4469.216716        4466.955473   \n",
       "1     BTC       6903.840000         7910.455075        7901.675124   \n",
       "2     BTC       8051.415000         4575.811592        4587.443980   \n",
       "3     BTC       5355.911250         4512.795373        4506.320995   \n",
       "4     BTC       3947.572500         4905.297015        4890.617313   \n",
       "..    ...               ...                 ...                ...   \n",
       "61    BTC       4045.777500         4710.204776        4699.571393   \n",
       "62    BTC       5137.817500         4617.933333        4610.129204   \n",
       "63    BTC       7088.031250         4493.505323        4500.628308   \n",
       "64    BTC       4071.153750         4688.269602        4680.511443   \n",
       "65    BTC       5367.445000         4533.105970        4526.545075   \n",
       "\n",
       "    rolling_20_day_std  bollinger_band_lower  bollinger_band_upper  \\\n",
       "0           996.010342           3470.945131           5462.965815   \n",
       "1          1377.102412           6524.572712           9278.777536   \n",
       "2          1284.345026           3303.098954           5871.789006   \n",
       "3          1055.109045           3451.211950           5561.430040   \n",
       "4          1359.438495           3531.178818           6250.055808   \n",
       "..                 ...                   ...                   ...   \n",
       "61         1263.280727           3436.290666           5962.852120   \n",
       "62         1183.201823           3426.927381           5793.331027   \n",
       "63         1084.723988           3415.904320           5585.352296   \n",
       "64         1251.787127           3428.724316           5932.298570   \n",
       "65         1082.471052           3444.074023           5609.016127   \n",
       "\n",
       "    tweet_date  pct_positive  pct_negative  pct_neutral  tweet_volume  \n",
       "0   2019-05-08      0.025641      0.000000     0.974359            39  \n",
       "1   2018-09-01      0.000000      0.000000     1.000000             1  \n",
       "2   2019-05-27      0.062903      0.012903     0.919355           620  \n",
       "3   2019-04-28      0.000000      0.000000     1.000000             1  \n",
       "4   2019-03-17      0.000000      0.000000     1.000000             1  \n",
       "..         ...           ...           ...          ...           ...  \n",
       "61  2019-03-31      0.000000      0.000000     1.000000             1  \n",
       "62  2019-04-12      0.500000      0.000000     0.500000             2  \n",
       "63  2019-05-16      0.000000      0.000000     1.000000             3  \n",
       "64  2019-04-02      0.000000      0.000000     1.000000             1  \n",
       "65  2019-04-25      0.000000      0.166667     0.833333             6  \n",
       "\n",
       "[66 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joined.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed4a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# sia.polarity_scores(\"this is awesome!\")\n",
    "# print(sia.polarity_scores(\"【毎日プレゼント企画】\"))\n",
    "# print(sia.polarity_scores('È appena uscito un nuovo video! LES CRYPTOMONNAIES QUI PULVÉRISENT BITCOIN EN 2019 https://t.co/yCsQMvRnyS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c56922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price to SMA Ratio\n",
    "# MACD (moving average converging divergence)\n",
    "# Bollinger Bands\n",
    "# RSI (Relative Strength Index)\n",
    "# Stochastic Oscillator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dca3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
